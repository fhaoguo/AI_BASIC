{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引用几个HMM的基本概念。\n",
    "\n",
    "1. 隐式状态，在本文中用H表示； \n",
    "2. 显式状态，在本文中用大写的英文字母O表示；\n",
    "3. 初始状态，在本文中用Pi表示。\n",
    "\n",
    "HMM的中，就是根据显式状态O来计算隐式状态H的概率的问题，其中在HMM中有一个基本的前提条件，那就是每一个time step的隐式状态只跟它前一步的的隐式状态有关。\n",
    "\n",
    "![](./files/HMM1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- observables是大家能直接得到的信息，例如一个句子\"哆啦A梦是猫型机器人\"，这个就是一个observable的sequence。\n",
    "- 如何才能够得到这句话背后所包含的隐式sequences呢？从上图可以看出hidden states之间是通过transition matrix来连接，每一步的hidden state仅仅是由前一步的hidden state来确定；hidden state和observable之间通过emission matrix来连接，即在给定的hidden state的情况的，指向每一个observable的概率是多少。\n",
    "\n",
    "![](./files/HMM2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    def __init__(self, N, M):\n",
    "        \"\"\"Args:\n",
    "            N: 状态数，这里对应存在的标注的种类\n",
    "            M: 观测数，这里对应有多少不同的字\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "\n",
    "        # 状态转移概率矩阵 A[i][j]表示从i状态转移到j状态的概率\n",
    "        self.A = torch.zeros(N, N)\n",
    "        # 观测概率矩阵, B[i][j]表示i状态下生成j观测的概率\n",
    "        self.B = torch.zeros(N, M)\n",
    "        # 初始状态概率  Pi[i]表示初始时刻为状态i的概率\n",
    "        self.Pi = torch.zeros(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    def __init__(self, N, M):\n",
    "        pass\n",
    "    def train(self, word_lists, tag_lists, word2id, tag2id):\n",
    "        \"\"\"HMM的训练，即根据训练语料对模型参数进行估计,\n",
    "           因为我们有观测序列以及其对应的状态序列，所以我们\n",
    "           可以使用极大似然估计的方法来估计隐马尔可夫模型的参数\n",
    "        参数:\n",
    "            word_lists: 列表，其中每个元素由字组成的列表，如 ['担','任','科','员']\n",
    "            tag_lists: 列表，其中每个元素是由对应的标注组成的列表，如 ['O','O','B-TITLE', 'E-TITLE']\n",
    "            word2id: 将字映射为ID\n",
    "            tag2id: 字典，将标注映射为ID\n",
    "        \"\"\"\n",
    "\n",
    "        assert len(tag_lists) == len(word_lists)\n",
    "\n",
    "        # 估计转移概率矩阵\n",
    "        for tag_list in tag_lists:\n",
    "            seq_len = len(tag_list)\n",
    "            for i in range(seq_len - 1):\n",
    "                current_tagid = tag2id[tag_list[i]]\n",
    "                next_tagid = tag2id[tag_list[i+1]]\n",
    "                self.A[current_tagid][next_tagid] += 1\n",
    "        # 一个重要的问题：如果某元素没有出现过，该位置为0，这在后续的计算中是不允许的\n",
    "        # 解决方法：我们将等于0的概率加上很小的数\n",
    "        self.A[self.A == 0.] = 1e-10\n",
    "        self.A = self.A / self.A.sum(dim=1, keepdim=True)\n",
    "\n",
    "        # 估计观测概率矩阵\n",
    "        for tag_list, word_list in zip(tag_lists, word_lists):\n",
    "            assert len(tag_list) == len(word_list)\n",
    "            for tag, word in zip(tag_list, word_list):\n",
    "                tag_id = tag2id[tag]\n",
    "                word_id = word2id[word]\n",
    "                self.B[tag_id][word_id] += 1\n",
    "        self.B[self.B == 0.] = 1e-10\n",
    "        self.B = self.B / self.B.sum(dim=1, keepdim=True)\n",
    "\n",
    "        # 估计初始状态概率\n",
    "        for tag_list in tag_lists:\n",
    "            init_tagid = tag2id[tag_list[0]]\n",
    "            self.Pi[init_tagid] += 1\n",
    "        self.Pi[self.Pi == 0.] = 1e-10\n",
    "        self.Pi = self.Pi / self.Pi.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
